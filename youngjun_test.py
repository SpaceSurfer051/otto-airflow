from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import NoSuchElementException, TimeoutException
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.keys import Keys
import time
import pandas as pd

def get_href_links(driver, wait, actions, num_items_to_fetch=100):
    href_links = set()
    while len(href_links) < num_items_to_fetch:
        actions.send_keys(Keys.END)
        time.sleep(2)
        
        for x in range(1, 46):
            try:
                xpath = f'//*[@id="root"]/main/div/section[3]/div[1]/div/div[{x}]/div/div[2]/a[2]'
                element = wait.until(EC.presence_of_element_located((By.XPATH, xpath)))
                href = element.get_attribute('href')
                href_links.add(href)
            except (NoSuchElementException, TimeoutException):
                continue

        print(f"Current number of unique href links: {len(href_links)}")
        if len(href_links) >= num_items_to_fetch:
            break

    return list(href_links)

def extract_reviews(driver, wait):
    actions = driver.find_element(By.CSS_SELECTOR, 'body')
    time.sleep(1)
    actions.send_keys(Keys.END)
    time.sleep(2)
    actions.send_keys(Keys.END)
    time.sleep(2)
    actions.send_keys(Keys.END)
    time.sleep(1)

    
    reviews = []
    for n in range(3, 10):
        try:
            review_id = wait.until(EC.presence_of_element_located((By.XPATH, f'//*[@id="style_estimate_list"]/div/div[{n}]/div[1]/div/div[1]/p[1]'))).text
            print(f"review_id: {review_id}")

            weight_height_gender = wait.until(EC.presence_of_element_located((By.XPATH, f'//*[@id="style_estimate_list"]/div/div[{n}]/div[1]/div/div[2]/p[1]'))).text
            print(f"weight_height_gender: {weight_height_gender}")
            
            top_size = wait.until(EC.presence_of_element_located((By.XPATH, f'//*[@id="style_estimate_list"]/div/div[{n}]/div[4]/div[1]/ul/li[1]/span'))).text
            print(f"top_size: {top_size}")
            brightness_comment = wait.until(EC.presence_of_element_located((By.XPATH, f'//*[@id="style_estimate_list"]/div/div[{n}]/div[4]/div[1]/ul/li[2]/span'))).text
            print(f"brightness_comment: {brightness_comment}")
            
            color_comment = wait.until(EC.presence_of_element_located((By.XPATH, f'//*[@id="style_estimate_list"]/div/div[{n}]/div[4]/div[1]/ul/li[3]/span'))).text
            print(f"color_comment: {color_comment}")
            
            thickness_comment = wait.until(EC.presence_of_element_located((By.XPATH, f'//*[@id="style_estimate_list"]/div/div[{n}]/div[4]/div[1]/ul/li[4]/span'))).text
            print(f"thickness_comment: {thickness_comment}")
            
            purchased_product_id = wait.until(EC.presence_of_element_located((By.XPATH, f'//*[@id="style_estimate_list"]/div/div[{n}]/div[2]/div[2]/a'))).get_attribute('href')
            print(f"purchased_product_id: {purchased_product_id}")
            
            purchased_size = wait.until(EC.presence_of_element_located((By.XPATH, f'//*[@id="style_estimate_list"]/div/div[{n}]/div[2]/div[2]/p/span'))).text
            print(f"purchased_size: {purchased_size}")
            
            comment = wait.until(EC.presence_of_element_located((By.XPATH, f'//*[@id="style_estimate_list"]/div/div[{n}]/div[4]/div[2]'))).text
            print(f"comment: {comment}")

            review = {
                "weight_height_gender": weight_height_gender,
                "review_id": review_id,
                "top_size": top_size,
                "brightness_comment": brightness_comment,
                "color_comment": color_comment,
                "thickness_comment": thickness_comment,
                "purchased_product_id": purchased_product_id,
                "purchased_size": purchased_size,
                "comment": comment
            }
            reviews.append(review)
        except (NoSuchElementException, TimeoutException):
            print(f"Review information not found for element index: {n}")
            continue
    
    return reviews

def get_product_info(driver, wait, href_links):
    products = []
    for index, link in enumerate(href_links):
        driver.get(link)
        time.sleep(2)  # í˜ì´ì§€ ë¡œë“œ ëŒ€ê¸°

        try:
            product_id = f"top{index + 1}"
            
            try:
                product_name = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id="root"]/div[3]/h2'))).text
            except (NoSuchElementException, TimeoutException):
                product_name = "N/A"
                print(f"Product name not found for link: {link}")
                
            try:
                category = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id="root"]/div[2]/a[1]'))).text
            except (NoSuchElementException, TimeoutException):
                category = "N/A"
                print(f"Category not found for link: {link}")

            try:
                price = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id="root"]/div[5]/div/div/span'))).text.strip()
            except (NoSuchElementException, TimeoutException):
                price = "N/A"
                print(f"Price not found for link: {link}")

            try:
                image_element = wait.until(EC.presence_of_element_located((By.XPATH, '//img[@class="sc-1jl6n79-4 AqRjD"]')))
                image_url = image_element.get_attribute('src')
            except (NoSuchElementException, TimeoutException):
                image_url = "N/A"
                print(f"Image URL not found for link: {link}")

            description = link

            # ì‚¬ì´ì¦ˆ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            sizes = []
            try:
                ul_element = wait.until(EC.presence_of_element_located((By.XPATH, '//ul[contains(@class, "sc-1sxlp32-1") or contains(@class, "sc-8wsa6t-1 Qtsoe")]')))
                li_elements = ul_element.find_elements(By.TAG_NAME, 'li')
                for li in li_elements:
                    size_text = li.text.strip()
                    if size_text not in ["cm", "MY"]:
                        sizes.append(size_text)
            except (NoSuchElementException, TimeoutException):
                print(f"Size information not found for link: {link}")

            # ë¦¬ë·° ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            reviews = extract_reviews(driver, wait)

            product = {
                "product_id": product_id,
                "product_name": product_name,
                "category": category,
                "price": price,
                "image_url": image_url,
                "description": description,
                "size": sizes,
                "reviews": reviews
            }
            products.append(product)
            
            # ë°ì´í„° ì¶œë ¥
            print(product)

        except Exception as e:
            print(f"Failed to extract data for link: {link} due to {e}")
            continue
    
    return products

def save_to_csv(products, filename="products.csv"):
    df = pd.DataFrame(products)
    df.to_csv(filename, index=False, encoding='utf-8-sig')
    print(f"Data saved to {filename}")

def main():
    URL = "https://www.musinsa.com/categories/item/001?device=mw&sortCode=emt_high"
    option = webdriver.ChromeOptions()
    option.add_experimental_option("excludeSwitches", ["enable-logging"])
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=option)
    driver.get(URL)
    time.sleep(3)

    driver.find_element(By.XPATH, '//*[@id="root"]/main/div/div[3]/div/button').click()
    time.sleep(1)

    wait = WebDriverWait(driver, 10)
    actions = driver.find_element(By.CSS_SELECTOR, 'body')

    href_links = get_href_links(driver, wait, actions, num_items_to_fetch=100)
    print(f"Number of unique href links: {len(href_links)}")

    products = get_product_info(driver, wait, href_links)
    print("Products extracted:")
    for product in products:
        print(product)

    save_to_csv(products)

    # driver.quit()

if __name__ == '__main__':
    main()
'''
êµ¬ì¡° - product
            product = {
                "product_id": product_id,
                "product_name": product_name,
                "category": category,
                "price": price,
                "image_url": image_url,
                "description": description,
                "size": sizes,
                "reviews": reviews
            }
êµ¬ì¡° - review           
            review = {
                "weight_height_gender": weight_height_gender,
                "review_id": review_id,
                "top_size": top_size,
                "brightness_comment": brightness_comment,
                "color_comment": color_comment,
                "thickness_comment": thickness_comment,
                "purchased_product_id": purchased_product_id,
                "purchased_size": purchased_size,
                "comment": comment
            }



ì˜ˆì‹œ ì¶œë ¥ - review
review_id: LV.3 ëˆ…ëˆ…ê°ì
weight_height_gender: ì—¬ì„± Â· 164cm Â· 74kg
top_size: ë³´í†µì´ì—ìš”
brightness_comment: ë³´í†µì´ì—ìš”
color_comment: ë³´í†µì´ì—ìš”
thickness_comment: ë³´í†µì´ì—ìš”
purchased_product_id: https://www.musinsa.com/app/goods/2612829/0
purchased_size: í™”ì´íŠ¸/M
comment: ì‘ì„ê¹Œë´ ê±±ì •í–ˆëŠ”ë° ë”± ë§ì•„ì„œ ì¢‹ì•„ìš”!! ì›ë‹¨ë„ ë‘ê»ì§€ ì•Šì•„ì„œ ì—¬ë¦„ì— ì˜ ì…ì„ ê²ƒ ê°™ìŠµë‹ˆë‹¹â— â€¿â— 
review_id: LV.3 ê¹€ë–¡ë»¥
weight_height_gender: ì—¬ì„± Â· 160cm Â· 57kg
top_size: ë³´í†µì´ì—ìš”
brightness_comment: ë³´í†µì´ì—ìš”
color_comment: ì„ ëª…í•´ìš”
thickness_comment: ì–‡ì•„ìš”
purchased_product_id: https://www.musinsa.com/app/goods/2612829/0
purchased_size: í™”ì´íŠ¸/S
comment: ğŸŒ± ì‚¬ì´ì¦ˆ: ì›ë˜ ì˜¤ë²„í•ì„ ì¦ê²¨ì…ëŠ” í¸ì¸ë° ì´ê±°ëŠ” ë‚¨ë…€ê³µìš©ì´ë¼ê·¸ëŸ°ì§€ Sì‚¬ì´ì¦ˆ ì…ì–´ë„ ì˜¤ë²„í•ì´ ì•„ì£¼ ì´ì˜ê³  ë‚­ë‚­í•˜ê²Œ ì˜ ë‚˜ì™€ìš”ğŸ¥¹
ğŸŒ± ì¬ì§ˆ, ë§ˆê°: ì¼ë°˜ì ì¸ ë©´ ì¬ì§ˆì´ê³  ë§ˆê° ê¹”ë”í•˜ê³  ëª©ë¶€ë¶„ì´ ì§±ì§±í•œê²Œ ì…ì„ë•Œë§ˆë‹¤ ëŠê»´ì ¸ìš”(ì´ê±° ì •ë§ ì¤‘ìš”í•œ ë””í…Œì¼ì¸ê±° ì•„ì‹œì£ )
ğŸŒ± ì°©ìš© í›„ ëŠë‚€ì  : ê¸°ë³¸í…œì´ë¼ ì†ì´ ì—„ì²­ ìì£¼ê°€ìš”. ì¼ì£¼ì¼ ë‚´ë‚´ ë‘ ì»¬ëŸ¬ ëŒë ¤ì…ê³  ìˆì–´ìš”ã…ã… ì–´ëŠ í•˜ì˜ë‘ ë§¤ì¹˜í•´ë„ ì»¬ëŸ¬ê°ì´ ì•„ì£¼ ì°°ë–¡ìœ¼ë¡œ ì˜ ì–´ìš¸ë¦¬ê³  ë„ˆë¬´ ì´ì©ë‹ˆë‹¤. ê·¸ë¦¬ê³  íŒ” ë¶€ë¶„ ë‘ ë²ˆ ì ‘ì–´ ì…ìœ¼ë©´ ëŠë‚Œì´ ì¢€ ë” í™œë™ì ì´ê³  í•ì´ ì´ë»ì ¸ìš”. ë‹¤ë“¤ ì ‘ì–´ì„œ ì…ì–´ë³´ì„¸ìš”ğŸ¤­ ë‚ ì´ ì¢€ ë” ì‹œì›í•´ì§€ë©´ ì´ë„ˆí‹°ë¡œ ìŠ¤íƒ€ì¼ë§ í•´ë„ ì•„ì£¼ê·¸ëƒ¥ ì´ì ê±°ê°™ì•„ìš”.
ğŸŒ± ê°€ì„±ë¹„: êµ¬ë§¤í•  ë•Œ í‹° 2ê°œë¥¼ 3ë§Œì› ëŒ€ì— êµ¬ë§¤í•´ì„œ ì´ë ‡ê²Œ ë§¤ì¼ ì…ëŠ”ê±°ë³´ë©´ ê°€ì„±ë¹„ íƒ‘ì…ë‹ˆë‹¤ğŸ¥¹ ì´ëŸ° ê¸°ë³¸í‹°ëŠ” ì„¸ì¼ì´ë‚˜ íŠ¹ê°€ ëœ° ë•Œë§ˆë‹¤ ìŸì—¬ë†”ì•¼ í•˜ëŠ”ê±° ì•„ì‹œì£ ?! ê¼­ ì‚¬ì„¸ìš” ë‹¤ëœâ¤ï¸



ì˜ˆì‹œ ì¶œë ¥ - products

{'product_id': 'top4', 
'product_name': '[ë² ì´ì§ OR ë§ê±° ì„ íƒ] [SET] CGP ì•„ì¹˜ ë¡œê³  í‹°ì…”ì¸ ', 
'category': 'ìƒì˜', 
'price': '45,900ì›',
'image_url': 'https://image.msscdn.net/images/goods_img/20220614/2612829/2612829_17193674550457_500.jpg', 
'description': 'https://www.musinsa.com/app/goods/2612829', '
size': ['S', 'M', 'L', 'XL']


ì•„ì§ ìƒ‰ê¹”ì •ë³´ ë¯¸í¬í•¨í–ˆê³ , í…ŒìŠ¤íŠ¸ì½”ë“œë¼ì„œ ì“¸ëŒ€ì—†ëŠ” printê°€ ë§ìŠµë‹ˆë‹¤.

'''

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Using cached boto3-1.34.145-py3-none-any.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: botocore in c:\\users\\dldud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.34.29)\n",
      "Collecting s3transfer\n",
      "  Using cached s3transfer-0.10.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting botocore\n",
      "  Using cached botocore-1.34.145-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\dldud\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\dldud\\appdata\\roaming\\python\\python311\\site-packages (from botocore) (2.8.2)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in c:\\users\\dldud\\appdata\\roaming\\python\\python311\\site-packages (from botocore) (1.26.18)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dldud\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore) (1.16.0)\n",
      "Using cached boto3-1.34.145-py3-none-any.whl (139 kB)\n",
      "Using cached botocore-1.34.145-py3-none-any.whl (12.4 MB)\n",
      "Using cached s3transfer-0.10.2-py3-none-any.whl (82 kB)\n",
      "Installing collected packages: botocore, s3transfer, boto3\n",
      "  Attempting uninstall: botocore\n",
      "    Found existing installation: botocore 1.34.29\n",
      "    Uninstalling botocore-1.34.29:\n",
      "      Successfully uninstalled botocore-1.34.29\n",
      "Successfully installed boto3-1.34.145 botocore-1.34.145 s3transfer-0.10.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "awsebcli 3.20.10 requires botocore<1.32.0,>1.23.41, but you have botocore 1.34.145 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install boto3 botocore s3transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "\n",
    "# AWS S3 버킷 정보\n",
    "bucket_name = 'papalio-test-bucket'\n",
    "file_key = 'test_otto/products_with_size_color.csv'\n",
    "\n",
    "# S3 클라이언트 생성\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# S3에서 CSV 파일 다운로드\n",
    "try:\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
    "    content = response['Body'].read().decode('utf-8')\n",
    "    \n",
    "    # CSV 내용을 데이터프레임으로 변환\n",
    "    df = pd.read_csv(io.StringIO(content))\n",
    "    \n",
    "    # 데이터프레임 출력\n",
    "    #print(df)\n",
    "    #df csv파일로 만들기\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error reading S3 object: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "import json\n",
    "\n",
    "'''\n",
    "이 단은 product table을 전처리하는 부분임\n",
    "'''\n",
    "\n",
    "#production preprocessing\n",
    "df['product_id'] = df.index.to_series().apply(lambda x: f'top_{x}')\n",
    "# price 열의 데이터를 전처리\n",
    "for i in range(len(df)):\n",
    "    price_value = df.loc[i, 'price']\n",
    "    # 빈칸을 기준으로 앞부분만 남기고 나머지 제거\n",
    "    price_value = price_value.split(' ')[0]\n",
    "    # 숫자와 쉼표만 남기기\n",
    "    price_value = re.sub(r'[^\\d,]', '', price_value)\n",
    "    df.loc[i, 'price'] = price_value\n",
    "\n",
    "\n",
    "#color_options 비우기\n",
    "\n",
    "#category를 전부 top으로 바꾸기\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"preprocessing_test.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting ',' delimiter: line 1 column 549 (char 548)\n",
      "Error decoding JSON: Expecting ',' delimiter: line 1 column 1827 (char 1826)\n",
      "Error decoding JSON: Expecting ',' delimiter: line 1 column 436 (char 435)\n",
      "Error decoding JSON: Invalid \\escape: line 1 column 1440 (char 1439)\n",
      "Saved all reviews to musinsa_reviews.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# CSV 파일 읽기\n",
    "df = pd.read_csv('preprocessing_test.csv')\n",
    "\n",
    "# reviews 컬럼의 JSON 데이터를 파싱하는 함수\n",
    "def parse_reviews(review_str):\n",
    "    try:\n",
    "        return json.loads(review_str.replace(\"'\", '\"'))\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        return []\n",
    "\n",
    "# 모든 리뷰를 담을 리스트\n",
    "all_reviews = []\n",
    "\n",
    "# 각 product_name별로 리뷰를 추출하여 통합\n",
    "for index, row in df.iterrows():\n",
    "    product_name = row['product_name']\n",
    "    reviews_list = parse_reviews(row['reviews'])\n",
    "    \n",
    "    for review in reviews_list:\n",
    "        review['product_name'] = product_name  # 각 리뷰에 제품 이름 추가\n",
    "        all_reviews.append(review)\n",
    "        \n",
    "# 통합 리뷰 데이터를 데이터프레임으로 변환\n",
    "reviews_df = pd.DataFrame(all_reviews)\n",
    "\n",
    "# weight, height, gender를 분리하여 새로운 컬럼 생성\n",
    "def split_weight_height_gender(whg):\n",
    "    parts = whg.split(' · ')\n",
    "    if len(parts) == 3:\n",
    "        gender, height, weight = parts\n",
    "        height = height.replace('cm', '')\n",
    "        weight = weight.replace('kg', '')\n",
    "        return gender.strip(), height.strip(), weight.strip()\n",
    "    return None, None, None\n",
    "\n",
    "reviews_df['gender'], reviews_df['height'], reviews_df['weight'] = zip(*reviews_df['weight_height_gender'].map(split_weight_height_gender))\n",
    "\n",
    "# 컬럼명 변경\n",
    "reviews_df.rename(columns={'top_size': 'size_option', 'purchased_size': 'size'}, inplace=True)\n",
    "\n",
    "# 새로운 컬럼 top_size와 bottom_size 생성\n",
    "reviews_df['top_size'] = 'none'\n",
    "reviews_df['bottom_size'] = 'none'\n",
    "# 컬럼 삭제\n",
    "reviews_df.drop(columns=['weight_height_gender'], inplace=True)\n",
    "\n",
    "# 통합 리뷰 데이터를 CSV 파일로 저장\n",
    "reviews_df.to_csv('musinsa_reviews.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"Saved all reviews to musinsa_reviews.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error decoding JSON: Expecting ',' delimiter: line 1 column 549 (char 548)\n",
      "Error decoding JSON: Expecting ',' delimiter: line 1 column 1827 (char 1826)\n",
      "Error decoding JSON: Expecting ',' delimiter: line 1 column 436 (char 435)\n",
      "Error decoding JSON: Invalid \\escape: line 1 column 1440 (char 1439)\n",
      "Saved all reviews to musinsa_reviews.csv\n",
      "Saved processed products to processed_products.csv\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "이 코드는 내 전처리 파트임.\n",
    "'''\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "import json\n",
    "\n",
    "# AWS S3 버킷 정보\n",
    "bucket_name = 'papalio-test-bucket'\n",
    "file_key = 'test_otto/products_with_size_color.csv'\n",
    "\n",
    "# S3 클라이언트 생성\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# S3에서 CSV 파일 다운로드\n",
    "try:\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
    "    content = response['Body'].read().decode('utf-8')\n",
    "    \n",
    "    # CSV 내용을 데이터프레임으로 변환\n",
    "    df = pd.read_csv(io.StringIO(content))\n",
    "    \n",
    "    # 데이터프레임 출력\n",
    "    #print(df)\n",
    "    #df csv파일로 만들기\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error reading S3 object: {e}\")\n",
    "\n",
    "# Production preprocessing\n",
    "df['product_id'] = 'none'\n",
    "df.insert(0, 'rank', [i for i in range(0, len(df))])\n",
    "\n",
    "# price 열의 데이터를 전처리\n",
    "for i in range(len(df)):\n",
    "    price_value = df.loc[i, 'price']\n",
    "    # 빈칸을 기준으로 앞부분만 남기고 나머지 제거\n",
    "    price_value = price_value.split(' ')[0]\n",
    "    # 숫자와 쉼표만 남기기\n",
    "    price_value = re.sub(r'[^\\d,]', '', price_value)\n",
    "    df.loc[i, 'price'] = price_value\n",
    "\n",
    "# color_options 비우기\n",
    "df['color_options'] = 'none'\n",
    "\n",
    "# category를 전부 'top'으로 바꾸기\n",
    "df['category'] = 'top'\n",
    "df.drop(columns=['size_options'],inplace=True)\n",
    "\n",
    "\n",
    "# 리뷰 데이터 전처리\n",
    "# reviews 컬럼의 JSON 데이터를 파싱하는 함수\n",
    "def parse_reviews(review_str):\n",
    "    try:\n",
    "        return json.loads(review_str.replace(\"'\", '\"'))\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error decoding JSON: {e}\")\n",
    "        return []\n",
    "\n",
    "# 모든 리뷰를 담을 리스트\n",
    "all_reviews = []\n",
    "\n",
    "# 각 product_name별로 리뷰를 추출하여 통합\n",
    "for index, row in df.iterrows():\n",
    "    product_name = row['product_name']\n",
    "    reviews_list = parse_reviews(row['reviews'])\n",
    "    \n",
    "    for review in reviews_list:\n",
    "        review['product_name'] = product_name  # 각 리뷰에 제품 이름 추가\n",
    "        all_reviews.append(review)\n",
    "        \n",
    "# 통합 리뷰 데이터를 데이터프레임으로 변환\n",
    "reviews_df = pd.DataFrame(all_reviews)\n",
    "\n",
    "# weight, height, gender를 분리하여 새로운 컬럼 생성\n",
    "def split_weight_height_gender(whg):\n",
    "    parts = whg.split(' · ')\n",
    "    if len(parts) == 3:\n",
    "        gender, height, weight = parts\n",
    "        height = height.replace('cm', '')\n",
    "        weight = weight.replace('kg', '')\n",
    "        return gender.strip(), height.strip(), weight.strip()\n",
    "    return None, None, None\n",
    "\n",
    "reviews_df['gender'], reviews_df['height'], reviews_df['weight'] = zip(*reviews_df['weight_height_gender'].map(split_weight_height_gender))\n",
    "\n",
    "# weight_height_gender 컬럼 삭제\n",
    "reviews_df.drop(columns=['weight_height_gender'], inplace=True)\n",
    "\n",
    "# 컬럼명 변경\n",
    "reviews_df.rename(columns={'top_size': 'size_option', 'purchased_size': 'size'}, inplace=True)\n",
    "reviews_df.drop(columns=['purchased_product_id'],inplace=True)\n",
    "\n",
    "# 새로운 컬럼 top_size와 bottom_size 생성\n",
    "reviews_df['top_size'] = 'none'\n",
    "reviews_df['bottom_size'] = 'none'\n",
    "df.drop(columns=['reviews'],inplace=True)\n",
    "# 통합 리뷰 데이터를 CSV 파일로 저장\n",
    "reviews_df.to_csv('musinsa_reviews.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"Saved all reviews to musinsa_reviews.csv\")\n",
    "\n",
    "# 변경된 product 테이블도 CSV 파일로 저장\n",
    "df.to_csv('processed_products.csv', index=False, encoding='utf-8-sig')\n",
    "print(\"Saved processed products to processed_products.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
